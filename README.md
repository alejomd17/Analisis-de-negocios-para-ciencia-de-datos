# Análisis de Negocios para Ciencia de Datos

- Sílvia Ariza Sentís

<div align="center"> 
  <img src="https://static.platzi.com/media/achievements/badge-analisis-negocios-ciencia-datos-3b97d868-a43a-47ac-a2dc-0c0e6cb63f48.png" width="15%">
</div>

Tabla de Contenidos
===================

* [El mundo de los datos: data science y machine learning](#el-mundo-de-los-datos-data-science-y-machine-learning)
  * [¿Qué es ciencia de datos y big data?¿Cómo afectan a mi negocio?](#qué-es-ciencia-de-datos-y-big-datac\xC3\xB3mo-afectan-a-mi-negocio)
  * [¿Qué tipo de información podemos analizar?](#qu\xC3\xA9-tipo-de-informaci\xC3\xB3n-podemos-analizar)
  * [¿Cómo crear empresas y culturas data driven?](#c\xC3\xB3mo-crear-empresas-y-culturas-data-driven)

Created by [gh-md-toc](https://github.com/ekalinin/github-markdown-toc)

# El mundo de los datos: data science y machine learning

## ¿Qué es ciencia de datos y big data?¿Cómo afectan a mi negocio?

El big data simplemente se traduce como datos grandes, sin embargo no hay una definición especifica de que significa *grande*.
Algunos dicen que a partir de un millón de registros, podríamos decir que es cuando excel se bloquea y se necesiten herramientas alternativas.

Las entidades con más información son las empresas y gobiernos, ya que diariamente se almacenan datos de todos origenes, como podrían ser de los clientes, productos, transacciones, proveedores, etc.

Es por eso que entre tanta información surgió la necesidad de tener especialistas que analicen estos datos y poder tomar decisiones en base a estas.

Dentro de la información que podemos encontrar, serán principalmente númerica, sin embargo tambien existirán datos en forma de texto, imagenes, etc.

En esencia podemos decir que la labor de un *data scientist* es encontrar una solución matematica o estadistica para un problema de negocio.

## ¿Qué tipo de información podemos analizar?

Los principales tipos de datos que podemos encontrar son:

* Personas

Estos datos se refieren a las que nos describen como seres humanos, desde las cosas más elementales como altura, peso, nacionalidad, dirección, etcetera. Hasta nuestros gustos, preferencias, que tipo de contenido consumimos, cuales contenidos nos gusta más, así como con quien nos gustá pasar más tiempo.

* Transacciones
  * Monetarias

Son las que tienen un flujo economico de por medio, como son las que hacemos con la tarjeta de debito o credito, donde los bancos pueden recolectar nuestras preferencias, gastos y necesidades, así como nuestra posibilidad de otorgarnos un credito con base en nuestras transacciones.

* No monetarias (*o no financieros*)

En este tipo podrían entrar las compañias de telefonos, que podrían analizar nuestro comportamiento de a quien llamamos, cuánto tiempo lo hacemos, y si empezamos a dejar nuestros patrones habituales es probable que dejemos de usar los servicios, por lo que es común que te llamen o contacten para que no abandones.

* Navegación Web

La navegación web está principalmente enfocada en las cookies que probablemente aceptamos sin leer, que incluyen todos los términos y condiciones de la página, donde nos advierten de la información que estarán recolectando, sin embargo como cliente o usuario no nos importa mucho, sin embargo como dueño de la página seguramente vas a querer monitorear todo lo que puedas, como quien entra, edad, género, tiempo que pasan en la página, paises, etc.

* Machine 2 Machine

Estos son los datos recolectados para un sistema entre maquina y maquina, como podría ser el GPS, donde tomamos ubicaciones de dispositivos para analizarlos y quizás obtener la mejor ruta.

* Biométricos

Estos datos nos identifican como personas unicas y que puede ser la sangre, la saliva e incluso la huella dactilar. Sin embargo estos datos nos abren un debate ético interesante sobre su uso y confidencialidad.

## ¿Cómo crear empresas y culturas data driven?

Los pasos para crear una cultura de toma de decisiones basadas en los datos en una empresa se da a partir de los siguientes puntos:

1. Crear una **cultura** de datos.

Debemos entender todos en la organización la importancia de recolectar datos y tomar decisiones basadas en los mismos. Los diferentes tipos de datos que se pueden recolectra de un cliente. Los empleados deben tener muy claro su importancia y responsabilidad con los mismos.

2. **Recolectar** información.

En esta etapa se pretende recolectar todo lo que podamos, implementar bases de datos efectivas, encargados, etc.

3. **Medir** todo.

Una vez que ya hemos empezado a recolectar debemos establecer las operaciones necesarias para medir el progreso de los datos, como crece, que se recolecta, donde hay más datos, toma mucho o poco tiempo, etc.

4. Datos **relevantes** y **precisos**.

Ya que vamos recolectando hay que establecer las prioridades en los datos que queremos recolectar ya que hay datos que no nos pueden ser utiles para su analisis. Además los datos tambien deben ser precisos conforme a el caso de estudio, esto quiere decir que nos deben dar la información justa que necesitamos tanto nosotros como el usuario.

5. Testear y crear **hipótesis**.

Debemos crear hipostesis a partir de nuestras intuiciones y posteriormente hacer una debida validación con los datos que hemos recolectado.

6. Desde los **insights** de datos a las **acciones**.

Ahora que ya hemos testeado, vamos a tener insights, descubrimientos que nos den la pauta para tomar acción con respecto a los mismos. En este momento estaremos tomando acción a partir de los datos, es decir, ser un ***datadriven***.

7. Cumplir las **regulaciones** de datos.

Los datos que recolectamos y analizamos deben ser tomados con total transparencia y legalidad con el usuario que los comparte, ya que es importante tener una ética profesional.

8. **Automatizar**.

Finalmente algo importante es que debemos ser capaces de llevar a cabo este proceso con menor tiempo y mucha más eficacia, por lo que automatizar nos permitirá hacer o validar la misma hipotesis una y otra vez. Así como recolectar los datos al momento.

## ¿Qué es inteligencia artificial y machine learning?

### Contexto

El origen viene de IBM para crear un algoritmo/maquina que jugará ajedrez de tal forma que pudiera ganarle al actual campeón. Para ello se hizo valer de la inteligencia artificial, para poder predecir los movimientos del contrincante y a partir de eso establecer su mejor estrategia.

Sin embargo en los primeros juegos contra el humano, la maquina perdia, sin embargo no terminaba ahí. En cada juego la maquina procesaba el juego anterior y *entrenaba* para poder predecir mejor la siguiente vez. Hasta que finalmente la maquina ganó y desde ahí ha mejorado y nunca ha perdido. Esto es debido a que la maquina podía predecir su mejor movimiento con 5 movimientos adelante.

**Machine Learning**

Una tecnología para encontrar patrones y analizar los datos, de tal forma que podemos clasificarlos o agruparlos. Sin embargo no toda la información viene en un datos tan claros.

**Deep Learning**

Es por ello que se puede utilizar el deep learning para convertir los datos más abstractos, como los pixeles de una imagen o incluso un video en datos valiosos o utiles de analizar.

### Machine Learning

Aprendizaje automatizado, tiene muchas aplicaciones.

- Detección de fraudes.

Este algoritmo detecta los comportamientos de un usuario respecto a sus finanzas. De tal forma que si alguien ya ha cometido fraude se entrena a la maquina para detectar el comportamiento hasta perfeccionarlo más y más.

- Búsqueda Web.

En este caso se toman las busquedas realizadas en el buscador y se asocia con otros tipos de comportamientos relacionados con la compra, de tal forma que si llegamos a buscar un producto en particular, seguramente en poco tiempo si es que no lo compras, te llegarán anuncios para que lo adquieras. En incluso las empresas saben el momento en que lo estás comprando.

- Anuncios a tiempo real.

Relacionado con el ejemplo anterior esto se puede llevar a otro nivel, pues incluso al momento de hacer una compra se puede sugerir productos relacionados que otros usuarios tambien adquirieron al momentos de realizar la compra, llegando a vender más en una transacción de lo que esperabas.

- Analisis de textos.

Esta aplicación nos permite analizar y entender los mensajes que hay detras de los textos, llegando a clasificarlos u obteniendo las palabras clave para mejorar la forma en que entendemos los textos de manera automatizada, y más profunda.

- Next best action

La traducción es la siguiente mejor acción, de tal forma que podemos llegar a entender mejor el comportamiento del usuario y adelantarnos a vender según la fase del ciclo del usuario.

## ¿Qué es deep learning? Análisis de imagen, audio y video.

El deep learning nos va a permitir el analisis profundo de imagenes, donde las maquinas hoy en día pueden hacerlo mejor y más rapido.

Nuestra capacidad de analisis de imagenes es limitado, ya que depende de nuestro contexto cultural, nivel de energía y capacidad visual. En cambio para una maquina esto es constante, y se le puede dotar de mayor información hasta perfeccionarse y lograr una efectividad del 99%. Mientras que nosotros mantenemos una efectividad de 95% en nuestro mejor estado de energía.

### Ejemplos de uso

**Shazam**

Un caso de uso es Shazam, que hace uso del deep learning para detectar el patrón de la música, o mejor dicho, las ondas de sonido, con el objetivo de comparar dicho patrón sobre todas las canciones conocidas en la base de datos. Además, no sólo la encuentra con mucha efectividad, sino que tambien nos sugiere canciones similares, o que pertenecen al mismo genero musical, y cada vez que escuchamos el modelo va aprendiendo si nos ha gustado o no las sugerencias.

**Tesla**

En el caso de Tesla, usa la inteligencia artificial para analizar los sensores y grabaciones del trayecto para permitir la autonomía de estos autos. Esto es impresionante por que en cada momento se analiza la información, para permitir que avance o se detenga, Tesla tambien tien una gran responsabilidad al distribuir esta tecnología, porque pueden suceder todo tipo de accidentes automovilisticos.

## Flujo de trabajo en ciencia de datos: fases, roles y oportunidades laborales.

Dentro de un equipo encargado de analizar los datos podemos encontrar diferentes roles:

- **Ing de dato** : Es una persona que se encarga de conectar los dispositivos, estableces la estructura encargado de **captar los datos y administrarlos**. Tambien cabe destacar que es el principal responsable de que los datos de un negocio existan. Las herramientas o skills que necesita son los siguientes:

  - Hacer APIs y eTLs
  - Conectores
  - Herramientas de SQL y NoSQL
- **Analista o Business Intelligence**: Este rol le pertenece a quien, a partir de los datos generados u obtendios por el Ing de datos, extrae la **información** importante para que nos pueda dar el **status actual** de la empresa. Para realizar su trabaho es necesario que:

  - Cree Dashboards o cuadros de control
  - Automatice la generación de los mismo.
  - Utilice SQL y Excel.
- **Data Scientist**: Este rol le pertenece a la persona que, al igual que el *Analista* extrae la información, pero además su enfoque esta en **predecir** el comportamiento de los datos valiendose de su background en matematicas, estadistica y probabilidad. Sus principales herramientas son:

  - Python y R

Finalmente estos roles dentro de un equipo de analisis de datos, no puede desarrollarse sólo debido a sus habilidades tecnicas y especificas. Para poder alinear los objetivos de este equipo con los de la organización es necesario que exista un Traductor:

- **Data Translator**: Esta persona se encarga de liderar al equipo de trabajo, para que su trabajo se haga de manera efectiva, y oportuna. Además debe ser capaz de interpretar los datos pero sobre todo:
  - Tener una comunicación efectiva con otros equipos de la organización
  - Ser Experto en las necesidades del negocio.

## Herramientas para cada etapa del análisis de datos.

Las herramientas utilizadas dependeran del rol o etapa del análisis de datos. Pero principalmente tenemos 3 herramientas:

- **SQL**:
  SQL es un lenguaje de programación para el manejo de datos. Su principal tarea en el analisis de datos, es la **extracción** de información y *síntesis* de la base de datos para saber sobre el pasado y el presente.

Su uso es principalmente por parte del ingeniero de datos y el analista de datos.

- **R**:
  Este lenguaje está enfocado principalmente en el ambito **estadistico**, y ciertamente al principio puede parecer algo complejo, sin embargo es bastante potente para el analisis y predicción de la información.

Además, el lenguaje R, nos permite generar un **análisis descriptivo y exploratorio**, esto quiere decir que nos permite extraer la información importante de hoy, así como inferir lo que pudiera ocurrir mañana.

Dentro de los principales packetes utilizados, esta *ggplot2* y *dplyr*. Estos paquetes sirven para la visualización de los datos en graficas con bastantes funcionalidades.

Finalmente los roles que utilizan esta herramienta, es pricipalmente el Cientifico de Datos.

- **Python**:
  Este lenguaje amado por mucho y envidiado por otros, tiene un enfoque hacia la **ingenieria**, por lo que es parecido a otros lenguajes de programación, al menos a los más recientes.

Además, al igual que R, su uso en el analisis de datos está enfocado en el **análisis descriptivo y exploratorio**. Sin embargo su uso se extiende más allá como lo es el Desarrollo Web y de Software.

Los paquetes más utilizados en el ambito de análisis de datos son *Pandas* y *Numpy*. Estos paquetes nos sirven para simplificar el manejo de la información así como el calculo que pudieramos hacer con el mismo.

Finalmente, los roles que más utilizan este lenguaje es el Cientifico de datos, y principalmente aquellos que ya tienen una cercanía con algún lenguaje de programación ya que es mucho más sencillo adaptarse a este nuevo.

## ¿Qué es y cómo usar una base de datos relacional con SQL?

Aprender SQL nos permite extraer información de una Base de Datos del tipo **Relacional**, que se caracteriza por organizar la información en tablas.

### Instrucciones de comandos SQL

***SELECT***

La instrucción select nos permite **OBTENER** información contenida en la base de datos. La estructura de la instrucción select es la siguiente:

**SELECT**  <NOMBRE_COLUMNAS>
**FROM**  <NOMBRE_DE_LA_TABLA>
**WHERE** < CONDICION >
**GROUP BY** <AGRUPAR_POR_EL_NUMERO_DE_COLUMNAS>
**ORDER BY** <COLUMNA_SOBRE_LA_CUAL_SE_ORDENA>

***Operadores Lógicos***
Estos operadores lógicos nos permiten estructurar condiciones mucho más complejas, como por ejemplo obtener los datos de los empleados que tienen más de 30 años **y** su nombre empiece con 'A'.

En este caso la palabra **'Y'** se traduce como ***'AND'*** en inglés y significa que ambas condicionales deben cumplirse. Además de *AND* existen otras condicionales como:

- **OR**: Evalua dos o más condicionales y sólo se cumple cuando **al menos** una de ellas se cumple, es decir, se puede cumplir sólo una condición, o todas.
- **NOT**: Excluye cierta información.
- **AND**: Evalua dos o más condicionales, y se deben cumplir todas.

***Funciones de agregación***

Nos sirven para encontrar datos especiales o calculos de columnas.

- **AVG**:  Para obtener el promedio de una columna.
- **COUNT**: Para obtener el número de registros en una columna.
- **DISTINCT**: Para encontrar valores únicos.
- **SUM**: Se suman todos los valores de una columna
- **MAX**: Sirve para encontrar el valor máximo de una columna.
- **MIN**: Sirve para encontrar el valor más bajo de una columna.

## Como estructurar una consulta SQL

Para realizar una consulta sencilla debemos identificar lo siguiente:

- ¿Qué es lo que queremos obtener? columna
- ¿De donde lo queremos obtener? tablas
- ¿Cuales son las restricciones o condiciones? condiciones

Una vez que identificamos cada parte se puede estructurar en una consulta.

```sql
select < columnas >

from < tablas > 

where  < condiciones >;
```

## Conflictos y retos actuales sobre la ética y el tratamiento de los datos.

Dentro del mundo de la minería y el tratamiento de los datos es importante identificar que datos pueden ser sensibles para el usuario y aquello que simplemente son generales. Además de identificar cuáles datos pueden ser sensibles para nosotros y con cuales nos sentimos comodos de compartir, ya que muchas veces no reflexionamos sobre la información que pudieran tener las aplicaciones debido a que nosotros lo permitimos.

Entonces de lo más importante es avisar al usuario de los datos que se utilizan dentro de las reglas de negocio así como el trato que se le dará a los mismos. Esto nos dará mayor tranquilidad y al usarlos, siempre con consentimiento del usuario.

## Aplica técnicas de storytelling para convertir problemas de datos en historias.

Para estructurar el problema que hemos resuelto de tal forma que todos sean capaces de entenderlo vamos a hacer uso de una técnica de story telling que nos ayuda a estructurar el problema en tres principales partes.

- **PROBLEMA**: Que es lo que está pasando que significa un obstaculo para el flujo correcto de la empresa.
- **SOLUCIÓN**: Explicar en terminos simples la forma en que se resolverá.
- **ALCANCE**: (Geografico y temporal) Hasta donde podemos llegar, y a quienes afectará, y en que momento, así como la manera de clasificarlos. ( lo máximo posible y con un aspecto personalizado. )

## Cómo estructurar un caso de negocio

Desglosar un problema de negocio en una hipótesis estructurada:

**¿Qué?** (Problema de negocio o  Hipótesis)

Partir de una pregunta específica.
**¿Por qué?**

Identificar todos los motivos y clasificarlo en pocas categorías, ejemplo:

* Motivaciones económicas
* Preguntas
* Problemas tecnológicos (relacionado con problema de como comunica la empresa).
* Política de la empresa.

**¿Cómo?**

Estrategia de cómo vamos a diseñar y organizar todo el análisis:

1.- **Análisis cuantitativo**.

Debe ir siempre primero ya que es toda la información y se trata de hacer una clasificación numérica.

2.- **Análisis cualitativo**.

Buscar categorías en función de texto. Nos ayuda a identificar características, tipos, relacionados con los objetos de estudio o analisis.

3.- **Matriz cuantitativa-cualitativa**.

Poner en conjunto la información, entender los números y explicarlos más a profundidad, incluso podemos empezar a comparar

4.- **Acciones de prevención**.

Definir acciones con la información que tenemos, tanto para prevenir como para contrarestar el problema. **Pasar de los insights a acciones**.

5.- **Validación**.

Verificar si nuestro análisis ha servido y si nuestras acciones de prevención están teniendo efecto, para ver que se puede mejorar.

## Análisis cuantitativo en un caso de negocio

Para este analisis nos enfocaremos en los números y lo primero es identificar las **variables cuantitativas** que nos ayudarán a resolver el ejercicio (las importantes).

Para esto podemos dividirlo en 3 pasos:

- **Descargar información**: En esta caso debemos filtrar a los objetos de estudio que entren en nuestro analisis, así como establecer macros que nos ayuden a replicar y dar un mayor alcance a este analisis, pueden ser **geograficos** y **temporales**.
- **Identificar**: Debemos establecer patrones de comportamiento, así como variables significativas que nos ayuden a caracterizar a nuestro objeto de estudio.
  Por ejemplo:
  - Madurez (compras realizadas)
  - Quejas mensuales
  - Compras mensuales (dinero)
  - Gasto mensual
  - Créditos y dinero devuelto
  - Margen operativo neto (Cuanto he ganado como empresa).
- **Definir**: Aqui tratamos de segmentar o clasificar a partir de las variables definidas en el paso anterior.
  Por ejemplo
  - Segmentacion según rentabilidad
  - Threshold(límite) Top Offender
  - Threshold(límite) para cada categoría
    - Clientes regulares
    - Clientes bronce
    - Clientes plata
    - Clientes dorados

Finalmente para llegar al objetivo debemos encontrar el limite para cada categoria, esto significa los clientes que provocan la mayoría de las quejas y para esto debemos segmentar por categoría y para cada categoría buscar los usuarios que más se quejan despues tomar los primeros y definir cuales son los principales. Podemos guiarnos del principio de pareto, el 80% de los resultados viene del 20% de las acciones, esto podría significar que el 80% de las quejas vienen del 20% de los usuarios, nuestra tarea es identificar esté 20%, pero sólo es un número inclusive podría ser menos del 20% de los usuarios.

## Análisis cualitativo en un caso de negocio.

Para este caso debemos identificar las **variables cualitativas** que nos ayudarán a resolver el ejercicio, se trata de un analisis categorico.

Para este caso nos centraremos en buscar la principal motivación de los usuarios que se quejan en exceso, o en otras palabras, que cumplen con la problematica del caso de estudio. Por lo tanto tenemos como primer paso:

- **Clusterizar**: Se trata de buscar las causas de contacto, aquello que podría provocar el problema de acuerdo a un comportamiento.

  - Motivaciones económicas
  - Preguntas
  - Problemas tecnológicos
  - Política de empresa
- **Clasificar**: Causas de los TO(Threhold Offenders) identificados.Para esta clusterización es necesario que usemos analisis de textos, palabras clave, etc.
- **Profundizar:** motivos de contacto con contexto.

  Posteriormente debemos tener en cuenta el contexo socioeconomico para evitar caer en sesgos y comprender aún mejor la causa.

## Fusión cuanti-cualitativa en un caso de negocio.

Para esta etapa del analisis ya hemos identificado quienes son los TO y tambien hemos identificado las posibles motivaciones de su causa, es decir ya contamos con las variables cuantitativas y cualitativas más importantes para el caso de estudio.



Ahora, lo que tenemos que hacer es resolver de manera conjunta la información cuantitativa y cualitativa para sacar conclusiones.
